{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow_examples.lite.model_maker.core.export_format import ExportFormat\n",
    "from tensorflow_examples.lite.model_maker.core.task import image_preprocessing\n",
    "\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker import ImageClassifierDataLoader\n",
    "from tflite_model_maker.image_classifier import ModelSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the cassava plant disease dataset and splits into training, validation and test datasets\n",
    "\n",
    "tfds_name = 'cassava'\n",
    "# tfdsload function is used to load the dataset cassava as well as the splits to load \n",
    "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
    "    name=tfds_name,\n",
    "    split=['train', 'validation', 'test'],\n",
    "    with_info=True,\n",
    "    # loads the dataset in a format that can be used for supervised learning \n",
    "    as_supervised=True)\n",
    "TFLITE_NAME_PREFIX = tfds_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the list of labels and loads the training and validation datasets\n",
    "\n",
    "label_names = ds_info.features['label'].names\n",
    "\n",
    "train_data = ImageClassifierDataLoader(ds_train,\n",
    "                                       ds_train.cardinality(),\n",
    "                                       label_names)\n",
    "validation_data = ImageClassifierDataLoader(ds_validation,\n",
    "                                            ds_validation.cardinality(),\n",
    "                                            label_names)\n",
    "\n",
    "# This selects the name of the model to use (mobilenet v3)\n",
    "\n",
    "model_name = 'mobilenet_v3_large_100_224' \n",
    "\n",
    "# this maps specific model name to the URLs for their crresponding pre-trained weights to the tensorflow hub \n",
    "map_model_name = {\n",
    "    'cropnet_cassava':\n",
    "        'https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1',\n",
    "    'cropnet_concat':\n",
    "        'https://tfhub.dev/google/cropnet/feature_vector/concat/1',\n",
    "    'cropnet_imagenet':\n",
    "        'https://tfhub.dev/google/cropnet/feature_vector/imagenet/1',\n",
    "    'mobilenet_v3_large_100_224':\n",
    "        'https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5',\n",
    "}\n",
    "\n",
    "model_handle = map_model_name[model_name]\n",
    "\n",
    "image_model_spec = ModelSpec(uri=model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model by training the model with the training dataset\n",
    "\n",
    "model = image_classifier.create(\n",
    "    train_data,  # train_data: the training data, which should be a tf.data.Dataset object containing labeled images\n",
    "    model_spec=image_model_spec,\n",
    "    batch_size=64,  # the number of images to be processed in each batch during training.\n",
    "    learning_rate=0.03, # the learning rate used by the optimizer during training.\n",
    "    epochs=1, #the number of times to iterate over the entire training dataset during training.\n",
    "    shuffle=True, # If True, all layers of the model are trainable\n",
    "    train_whole_model=True,  # if False, only the classification layer is trainable.\n",
    "    validation_data=validation_data)\n",
    "\n",
    "# model.model.save('/tmp/my_model.h5')\n",
    "# s3.upload_file('/tmp/my_model.h5', buket, object_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a mapping dictionary of the disease codes to names\n",
    "\n",
    "name_map = dict(\n",
    "    cmd='Mosaic Disease',\n",
    "    cbb='Bacterial Blight',\n",
    "    cgm='Green Mite',\n",
    "    cbsd='Brown Streak Disease',\n",
    "    healthy='Healthy',\n",
    "    unknown='Unknown')\n",
    "\n",
    "[(name_map[x],x) for x in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions off the standard test dataset split from cassava \n",
    "\n",
    "test_data = ImageClassifierDataLoader(ds_test, ds_test.cardinality(),\n",
    "                                      label_names)\n",
    "model.predict_top_k(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the image files from Amazon S3\n",
    "import boto3\n",
    "import io\n",
    "# loading the the downloaded images as Numpy arrays \n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Read the bucket name from input.log, used to create or update a table with same name\n",
    "with open('/home/ubuntu/ML/input.log', 'r') as file:\n",
    "    bucket_name = file.read().replace('\\n', '')\n",
    "\n",
    "# boto3 resource using default credentials in .aws\n",
    "s3 = boto3.resource('s3', region_name='us-west-2')\n",
    "\n",
    "# the bucket that triggered the lambda based on the timestamp upload event\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name='us-west-2')\n",
    "# Get the contents of the time_stamp.txt object in the bucket\n",
    "timestamp_obj = s3_client.get_object(Bucket=bucket_name, Key='time_stamp.txt')\n",
    "timestamp = timestamp_obj['Body'].read().decode('utf-8').strip()\n",
    "\n",
    "# ses setup\n",
    "email_client = boto3.client(\"ses\", region_name=\"us-west-2\")\n",
    "\n",
    "# dict for storing images\n",
    "images = {}\n",
    "\n",
    "# list for storing each plant_id\n",
    "plant_ids = []\n",
    "\n",
    "# get all objects from the bucket\n",
    "summaries = bucket.objects.all()\n",
    "\n",
    "# loop through all objects in the bucket\n",
    "for f in summaries:\n",
    "    # BytesIO object holds image data\n",
    "    bstream = io.BytesIO()\n",
    "\n",
    "    # check if the current object is a JPEG\n",
    "    if str(f.key).upper().endswith(\".JPG\") or str(f.key).upper().endswith(\".JPEG\"):\n",
    "        # download image into the BytesIO object\n",
    "        bucket.Object(f.key).download_fileobj(bstream)\n",
    "\n",
    "        # read image data and store it in the images dict\n",
    "        images[f.key] = mpimg.imread(bstream, format=\"JPEG\")\n",
    "        # extract the number from the image file name, file name will always be formatted as \"Plant_{N}\", where {N} is any number\n",
    "        plant_id = f.key.split('_')[1].split('.')[0] # split the string on the underscore, split the remaining string on the dot, select the string before the dot \n",
    "        plant_ids.append(plant_id)\n",
    "        print(f\"{f.key}, id = {plant_id}, current # of id's = {len(plant_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a new dataset using my image files \n",
    "v = [x for x in images.values() if x.shape[0] == 256 and x.shape[1] == 256] #list(images.values())\n",
    "\n",
    "input_1 = np.array(v) #np.array(list(images.values())) #np.array((img1, img2))\n",
    "input_2 = np.array([0]*len(v)) #np.array((0, 0))\n",
    "\n",
    "ds_test2 = tf.data.Dataset.from_tensor_slices((input_1, input_2))\n",
    "\n",
    "#tf.data.Dataset.from_tensor_slices([img1, img2])\n",
    "test_data2 = ImageClassifierDataLoader(ds_test2, ds_test2.cardinality(),\n",
    "                                      label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict whether the images have disease\n",
    "# Returns (label, probability)\n",
    "labels = [(name_map[x[0][0]], float(x[0][1])) for x in model.predict_top_k(test_data2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "from boto3.dynamodb.conditions import Key\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# dynamodb setup\n",
    "dynamodb = boto3.resource('dynamodb', region_name='us-west-2')\n",
    "table_name = bucket_name  # use the bucket_name as table_name\n",
    "\n",
    "# check if table exists\n",
    "try: \n",
    "    table = dynamodb.create_table(\n",
    "        TableName=table_name,\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'plant_id',\n",
    "                'KeyType': 'HASH' # this makes plant_id essentially the primary key\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'plant_id',\n",
    "                'AttributeType': 'S'\n",
    "            }\n",
    "        ],\n",
    "        ProvisionedThroughput={\n",
    "            'ReadCapacityUnits': 10,\n",
    "            'WriteCapacityUnits': 10\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # wait until the table is created\n",
    "    table.meta.client.get_waiter('table_exists').wait(TableName=table_name)\n",
    "    print(f\"Created {table_name} table\")\n",
    "except ClientError as ce:\n",
    "    if ce.response['Error']['Code'] == \"ResourceInUseException\":\n",
    "        print(f\"Table {table_name} already exists\")\n",
    "        table = dynamodb.Table(table_name)\n",
    "    else:\n",
    "        print(f\"Unknown exception occurred while querying for {table_name} table\")\n",
    "        print(ce)\n",
    "        \n",
    "# Get the labels for the test data using the trained model\n",
    "disease = True\n",
    "\n",
    "for plant_id, (label, probabilities) in zip(plant_ids, labels):\n",
    "    print(label)\n",
    "    if label == \"Healthy\":\n",
    "        diseased = False\n",
    "        \n",
    "    # check if the item exists in the table\n",
    "    response = table.query(\n",
    "        KeyConditionExpression=Key('plant_id').eq(plant_id)\n",
    "    )\n",
    "    items = response['Items']\n",
    "    \n",
    "    # table has matching items already\n",
    "    if items:\n",
    "        # update existing item\n",
    "        item = items[0]\n",
    "        item[\"metadata\"].append(\n",
    "            {\n",
    "                \"disease\": label,\n",
    "                \"probability\": Decimal(str(probabilities)),  \n",
    "                \"time_stamp\": timestamp\n",
    "            }\n",
    "        )\n",
    "        table.put_item(Item=item)\n",
    "    else:\n",
    "        # no existing item found, create one with new plant_id\n",
    "        item = {\n",
    "            \"plant_id\": plant_id,\n",
    "            \"metadata\": [\n",
    "                {\n",
    "                    \"disease\": label,\n",
    "                    \"probability\": Decimal(str(probabilities)),\n",
    "                    \"time_stamp\": timestamp \n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        table.put_item(Item=item)\n",
    "    \n",
    "    # body_data = str(garden_id) + \" - \" + label + \" detected\"\n",
    "    # body_page = \"\"\"\n",
    "    #     <html>\n",
    "    #     <head></head>\n",
    "    #     <body>\n",
    "    #     <h2>Disease Detected - \"\"\" + label + \"\"\"</h2>\"\"\" + \"\"\"\n",
    "    #     <p>Found in GardenId = \"\"\" + str(garden_id) + \"\"\"\n",
    "    #     </body>\n",
    "    #     </html> \"\"\"\n",
    "    # if diseased:\n",
    "    #     try:\n",
    "    #         email_client.send_email(Source=\"ttsega03@gmail.com\", \n",
    "    #                                Destination={\n",
    "    #                                    \"ToAddresses\": [\n",
    "    #                                        \"mesteddy14@gmail.com\"\n",
    "    #                                    ]\n",
    "    #                                }, Message={\n",
    "    #                                    \"Subject\": {\n",
    "    #                                        \"Data\": \"Disease Detected\",\n",
    "    #                                        \"Charset\": \"UTF-8\"\n",
    "    #                                    },\n",
    "    #                                    \"Body\": {\n",
    "    #                                        \"Text\": {\n",
    "    #                                            \"Data\": body_data,\n",
    "    #                                            \"Charset\": \"UTF-8\"\n",
    "    #                                        },\n",
    "    #                                        \"Html\": {\n",
    "    #                                            \"Data\": body_page,\n",
    "    #                                            \"Charset\": \"UTF-8\"\n",
    "    #                                        }\n",
    "    #                                    }\n",
    "    #                                }\n",
    "    #                                )\n",
    "    #     except Exception as e:\n",
    "    #         print(e)\n",
    "    # garden_id += 1\n",
    "    print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
