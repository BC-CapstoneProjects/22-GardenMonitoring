{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7245d10-379b-4017-be3f-75059b31b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_examples.lite.model_maker.core.export_format import ExportFormat\n",
    "from tensorflow_examples.lite.model_maker.core.task import image_preprocessing\n",
    "\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker import ImageClassifierDataLoader\n",
    "from tflite_model_maker.image_classifier import ModelSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1c6da10-c2ce-4af7-84ba-eb2e353a760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the cassava plant disease dataset and splits into training, validation and test datasets\n",
    "\n",
    "tfds_name = 'cassava'\n",
    "# tfdsload function is used to load the dataset cassava as well as the splits to load \n",
    "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
    "    name=tfds_name,\n",
    "    split=['train', 'validation', 'test'],\n",
    "    with_info=True,\n",
    "    # loads the dataset in a format that can be used for supervised learning \n",
    "    as_supervised=True)\n",
    "TFLITE_NAME_PREFIX = tfds_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b5ee8bb-7426-4176-8919-d2a675870eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the list of labels and loads the training and validation datasets\n",
    "\n",
    "label_names = ds_info.features['label'].names\n",
    "\n",
    "train_data = ImageClassifierDataLoader(ds_train,\n",
    "                                       ds_train.cardinality(),\n",
    "                                       label_names)\n",
    "validation_data = ImageClassifierDataLoader(ds_validation,\n",
    "                                            ds_validation.cardinality(),\n",
    "                                            label_names)\n",
    "\n",
    "# This selects the name of the model to use (mobilenet v3)\n",
    "\n",
    "model_name = 'mobilenet_v3_large_100_224' \n",
    "\n",
    "# this maps specific model name to the URLs for their crresponding pre-trained weights to the tensorflow hub \n",
    "map_model_name = {\n",
    "    'cropnet_cassava':\n",
    "        'https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1',\n",
    "    'cropnet_concat':\n",
    "        'https://tfhub.dev/google/cropnet/feature_vector/concat/1',\n",
    "    'cropnet_imagenet':\n",
    "        'https://tfhub.dev/google/cropnet/feature_vector/imagenet/1',\n",
    "    'mobilenet_v3_large_100_224':\n",
    "        'https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5',\n",
    "}\n",
    "\n",
    "model_handle = map_model_name[model_name]\n",
    "\n",
    "image_model_spec = ModelSpec(uri=model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03ad6ac3-4945-4970-9e9f-1227fbd4a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hub_keras_layer_v1v2_2 (Hub  (None, 1280)             4226432   \n",
      " KerasLayerV1V2)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,232,837\n",
      "Trainable params: 4,208,437\n",
      "Non-trainable params: 24,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "MODEL_WEIGHTS_FILE = 'trained_model_weights.h5'\n",
    "\n",
    "# Check if the model weights file exists\n",
    "if not os.path.exists(MODEL_WEIGHTS_FILE):\n",
    "    # Build the model by training the model with the training dataset\n",
    "    model = image_classifier.create(\n",
    "        train_data,\n",
    "        model_spec=image_model_spec,\n",
    "        batch_size=128,\n",
    "        learning_rate=0.03,\n",
    "        epochs=5,\n",
    "        shuffle=True,\n",
    "        train_whole_model=True,\n",
    "        validation_data=validation_data)\n",
    "\n",
    "    # Save the trained model's weights\n",
    "    model.model.save_weights(MODEL_WEIGHTS_FILE)\n",
    "else:\n",
    "    # Create a new model with the same architecture\n",
    "    new_model = image_classifier.create(\n",
    "        train_data,\n",
    "        model_spec=image_model_spec,\n",
    "        batch_size=128,\n",
    "        learning_rate=0.03,\n",
    "        epochs=0,  # Set epochs to 0 to avoid training\n",
    "        shuffle=True,\n",
    "        train_whole_model=True,\n",
    "        validation_data=validation_data)\n",
    "    \n",
    "    # Load the saved model's weights\n",
    "    new_model.model.load_weights(MODEL_WEIGHTS_FILE)\n",
    "    model = new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d8cecd6-78ef-41bc-9463-143209b68dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bacterial Blight', 'cbb'),\n",
       " ('Brown Streak Disease', 'cbsd'),\n",
       " ('Green Mite', 'cgm'),\n",
       " ('Mosaic Disease', 'cmd'),\n",
       " ('Healthy', 'healthy')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a mapping dictionary of the disease codes to names\n",
    "\n",
    "name_map = dict(\n",
    "    cmd='Mosaic Disease',\n",
    "    cbb='Bacterial Blight',\n",
    "    cgm='Green Mite',\n",
    "    cbsd='Brown Streak Disease',\n",
    "    healthy='Healthy',\n",
    "    unknown='Unknown')\n",
    "\n",
    "[(name_map[x],x) for x in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0f54a9-402d-43ab-a96c-379f08dbb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions off the standard test dataset split from cassava \n",
    "\n",
    "# test_data = ImageClassifierDataLoader(ds_test, ds_test.cardinality(),\n",
    "#                                       label_names)\n",
    "# model.predict_top_k(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dc3262e-e615-4254-82f6-8c4d788209ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchKey",
     "evalue": "An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14504/597629041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0ms3_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'us-west-2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Get the contents of the time_stamp.txt object in the bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtimestamp_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time_stamp.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestamp_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# loading the the downloaded images as Numpy arrays \n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Read the bucket name from input.log, used to create or update a table with same name\n",
    "# with open('/home/ubuntu/ML/input.log', 'r') as file:\n",
    "#     bucket_name = file.read().replace('\\n', '')\n",
    "bucket_name = 'planttest1234'\n",
    "s3 = boto3.resource('s3', region_name='us-west-2')\n",
    "bucket = s3.Bucket('planttest1234')\n",
    "\n",
    "s3_client = boto3.client('s3', region_name='us-west-2')\n",
    "# Get the contents of the time_stamp.txt object in the bucket\n",
    "timestamp_obj = s3_client.get_object(Bucket=bucket_name, Key='time_stamp.txt')\n",
    "timestamp = timestamp_obj['Body'].read().decode('utf-8').strip()\n",
    "\n",
    "# ses setup\n",
    "email_client = boto3.client(\"ses\", region_name=\"us-west-2\")\n",
    "\n",
    "# list for storing each plant_id\n",
    "plant_ids = []\n",
    "\n",
    "images = {}\n",
    "summaries = bucket.objects.all()\n",
    "for f in summaries:\n",
    "    bstream = io.BytesIO()\n",
    "    if str(f.key).upper().endswith(\".JPG\") or str(f.key).upper().endswith(\".JPEG\"):\n",
    "        bucket.Object(f.key).download_fileobj(bstream)\n",
    "        image = tf.image.decode_jpeg(bstream.getvalue(), channels=3)\n",
    "        \n",
    "        # Check if the image is the correct size\n",
    "        if image.shape[0] != 224 or image.shape[1] != 224:\n",
    "            # Resize the image to be 224x224\n",
    "            image = tf.image.resize(image, [224, 224])\n",
    "        \n",
    "        images[f.key] = image.numpy()\n",
    "        print(f.key)\n",
    "        images[f.key] = mpimg.imread(bstream, format=\"JPEG\")\n",
    "        # extract the number from the image file name, file name will always be formatted as \"Plant_{N}\", where {N} is any number\n",
    "        plant_id = f.key.split('_')[1].split('.')[0] # split the string on the underscore, split the remaining string on the dot, select the string before the dot \n",
    "        plant_ids.append(plant_id)\n",
    "        print(f\"{f.key}, id = {plant_id}, current # of id's = {len(plant_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04ae57-9358-4597-8c20-ea2c0a7488f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a new dataset using my image files \n",
    "v = [x for x in images.values() if x.shape[0] == 224 and x.shape[1] == 224 and x.shape[2] == 3]\n",
    "\n",
    "# Convert the list of images to a numpy array and normalize it to 0-1 range\n",
    "input_1 = np.stack(v, axis=0)  # Stack images along a new dimension to form a 4D tensor\n",
    "input_1 = input_1 / 255.0  # Normalize to 0-1 range\n",
    "\n",
    "# Get top-k predictions\n",
    "predicted_prob = model.model.predict(input_1)\n",
    "\n",
    "# Get the top-k predictions\n",
    "topk_prob, topk_id = tf.math.top_k(predicted_prob, k=1)\n",
    "\n",
    "# Map the label ids back to labels\n",
    "topk_label = np.array(label_names)[topk_id.numpy()]\n",
    "\n",
    "\n",
    "\n",
    "index_name_map = {i: name_map[name] for i, name in enumerate(label_names)}\n",
    "\n",
    "# Convert tensors to numpy arrays before using them as dictionary keys\n",
    "labels = [(index_name_map[x[0]], x[1]) for x in zip(topk_id.numpy().flatten(), topk_prob.numpy().flatten())]\n",
    "\n",
    "ds_test2 = tf.data.Dataset.from_tensor_slices((input_1, input_2))\n",
    "\n",
    "#tf.data.Dataset.from_tensor_slices([img1, img2])\n",
    "test_data2 = ImageClassifierDataLoader(ds_test2, ds_test2.cardinality(),\n",
    "                                      label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c92ff-8fdf-47b5-b884-16e537f482ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the images \n",
    "from PIL import Image as im\n",
    "\n",
    "i=0\n",
    "for d in v:\n",
    "    display(im.fromarray((d * 255).astype(np.uint8)))  # Convert normalized image back to 0-255 range\n",
    "    print(labels[i])\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf7d59d-a3b4-47bb-ab31-81a2468ba1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "from boto3.dynamodb.conditions import Key\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# dynamodb setup\n",
    "dynamodb = boto3.resource('dynamodb', region_name='us-west-2')\n",
    "table_name = bucket_name  # use the bucket_name as table_name\n",
    "\n",
    "# check if table exists\n",
    "try: \n",
    "    table = dynamodb.create_table(\n",
    "        TableName=table_name,\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'plant_id',\n",
    "                'KeyType': 'HASH' # this makes plant_id essentially the primary key\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'plant_id',\n",
    "                'AttributeType': 'S'\n",
    "            }\n",
    "        ],\n",
    "        ProvisionedThroughput={\n",
    "            'ReadCapacityUnits': 10,\n",
    "            'WriteCapacityUnits': 10\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # wait until the table is created\n",
    "    table.meta.client.get_waiter('table_exists').wait(TableName=table_name)\n",
    "    print(f\"Created {table_name} table\")\n",
    "except ClientError as ce:\n",
    "    if ce.response['Error']['Code'] == \"ResourceInUseException\":\n",
    "        print(f\"Table {table_name} already exists\")\n",
    "        table = dynamodb.Table(table_name)\n",
    "    else:\n",
    "        print(f\"Unknown exception occurred while querying for {table_name} table\")\n",
    "        print(ce)\n",
    "        \n",
    "# Get the labels for the test data using the trained model\n",
    "disease = True\n",
    "\n",
    "for plant_id, (label, probabilities) in zip(plant_ids, labels):\n",
    "    print(label)\n",
    "    if label == \"Healthy\":\n",
    "        diseased = False\n",
    "        \n",
    "    # check if the item exists in the table\n",
    "    response = table.query(\n",
    "        KeyConditionExpression=Key('plant_id').eq(plant_id)\n",
    "    )\n",
    "    items = response['Items']\n",
    "    \n",
    "    # table has matching items already\n",
    "    if items:\n",
    "        # update existing item\n",
    "        item = items[0]\n",
    "        item[\"metadata\"].append(\n",
    "            {\n",
    "                \"disease\": label,\n",
    "                \"probability\": Decimal(str(probabilities)),  \n",
    "                \"time_stamp\": timestamp\n",
    "            }\n",
    "        )\n",
    "        table.put_item(Item=item)\n",
    "    else:\n",
    "        # no existing item found, create one with new plant_id\n",
    "        item = {\n",
    "            \"plant_id\": plant_id,\n",
    "            \"metadata\": [\n",
    "                {\n",
    "                    \"disease\": label,\n",
    "                    \"probability\": Decimal(str(probabilities)),\n",
    "                    \"time_stamp\": timestamp \n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        table.put_item(Item=item)\n",
    "    \n",
    "    # body_data = str(garden_id) + \" - \" + label + \" detected\"\n",
    "    # body_page = \"\"\"\n",
    "    #     \n",
    "    #     \n",
    "    #     \n",
    "    #     Disease Detected - \"\"\" + label + \"\"\"\"\"\" + \"\"\"\n",
    "    #     Found in GardenId = \"\"\" + str(garden_id) + \"\"\"\n",
    "    #     \n",
    "    #      \"\"\"\n",
    "    # if diseased:\n",
    "    #     try:\n",
    "    #         email_client.send_email(Source=\"ttsega03@gmail.com\", \n",
    "    #                                Destination={\n",
    "    #                                    \"ToAddresses\": [\n",
    "    #                                        \"mesteddy14@gmail.com\"\n",
    "    #                                    ]\n",
    "    #                                }, Message={\n",
    "    #                                    \"Subject\": {\n",
    "    #                                        \"Data\": \"Disease Detected\",\n",
    "    #                                        \"Charset\": \"UTF-8\"\n",
    "    #                                    },\n",
    "    #                                    \"Body\": {\n",
    "    #                                        \"Text\": {\n",
    "    #                                            \"Data\": body_data,\n",
    "    #                                            \"Charset\": \"UTF-8\"\n",
    "    #                                        },\n",
    "    #                                        \"Html\": {\n",
    "    #                                            \"Data\": body_page,\n",
    "    #                                            \"Charset\": \"UTF-8\"\n",
    "    #                                        }\n",
    "    #                                    }\n",
    "    #                                }\n",
    "    #                                )\n",
    "    #     except Exception as e:\n",
    "    #         print(e)\n",
    "    # garden_id += 1\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59678658-b112-43fe-b559-8dbfe6267427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf28b44-e244-46c7-bf7e-4e4da6fc8bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f167be-d8e2-45f6-8cd1-c1c461085684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a202a-1717-4414-bd2e-2da9fbae243b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
